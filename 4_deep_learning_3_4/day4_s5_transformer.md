# 深層学習Day4 第五章 Transformer

- 18ヶ月で2倍の機械学習の計算量が必要になっている現実
- PC1台の性能を大幅アップさせるよりはPC複数台に分散処理させるほうが現実的手段

## 分散深層学習
- 深層学習は多くのデータを使用したり、パラメータ調整のために多くの時間を使用したりするため、高速な計算が求められる。
- 複数の計算資源(ワーカー)を使用し、並列的にニューラルネットを構成することで、効率の良い学習を行いたい。
- データ並列化、モデル並列化、GPUによる高速技術は不可欠である


## データ並列化のパターン
- 同期型：各ワーカーが計算が終わるのを待ち、全ワーカーの勾配が出たところで勾配の平均を計算し、親モデルのパラメータを更新する
- 非同期型：各ワーカーはお互いの計算を待たず、各子モデルごとに更新を行う。学習が終わった子モデルはパラメータサーバにPushされる。新たに学習を始める時は、パラメータサーバからPopしたモデルに対して学習していく

## 同期型と非同期型の比較
- 処理のスピードは、お互いのワーカーの計算を待たない非同期型の方が早い。
- 非同期型は最新のモデルのパラメータを利用できないので、学習が不安定になりやすい。-> Stale Gradient Problem
- 現在は同期型の方が精度が良いことが多いので、主流となっている。


## モデル並列化
- 親モデルを各ワーカーに分割し、それぞれのモデルを学習させる。全てのデータで学習が終わった後で、一つのモデルに復元。
- モデルが大きい時はモデル並列化を、データが大きい時はデータ並列化をすると良い


## GPUによる高速化
- CPU
    - 高性能なコアが少数
    - 複雑で連続的な処理が得意
- GPU
    - 比較的低性能なコアが多数
    - 簡単な並列処理が得意
    - ニューラルネットの学習は単純な行列演算が多いので、高速化が可能

## モデルの軽量化
- 代表的な手法として下記の3つがある
    - 量子化
    - 蒸留
    - プルーニング

---

# ハンズオン

- 該当するハンズオンはなし

---

# 気づき
- AIの分野でGPUが使われることはよく知っていたが、最近はビットコインの方が話題に上がっていて、そのせいでGPUの高騰化が激しかった。もしかしたらGPUの価格高騰化がAI業界にも少なからず影響を与えていたと思われる。
