# 深層学習Day3 第四章 双方向RNN

- 過去の情報だけでなく、未来の情報を加味することで、精度を向上させるためのモデル
- 学習時に、過去と未来の情報の入力を必要とすることから、運用時も過去から未来までのすべての情報を入力してはじめて予測できるようになる
- そのため応用範囲が限定される。

- 実用例
    - 文章の推敲
    - 機械翻訳
    - DNA塩基配列解析

## 演習チャレンジ

- （問題文は省略）
- （4）np.concatenate([h_f, h_b[::-1]], axis=1)
- 双方向RNNでは、順方向と逆方向に伝播したときの中間層表現をあわせたものが特徴量となるので、np.concatenate([h_f, h_b[::-1]], axis=1)である。
- 考察
    - np.concatenateは配列同士を結合するNumpy関数。関数を知らなかったのでまずは関数を覚える必要がある。

---

# ハンズオン

- 該当するハンズオン資料はなし

---

# 気づき
- 時系列の逆の相関を加味したモデルを考えたのは大変おもしろい考え方だと思うが、それに至った経緯は何だったのだろう。アイデアの力がすごい。
- これまでのRNN関連モデルのリンク
    - [再帰型ニューラルネットワーク(RNN) [LSTM, GRU, 双方向RNN]](https://cvml-expertguide.net/2020/05/17/rnn/)
    - [ニューラルネットワークで時系列データの予測を行う](https://qiita.com/icoxfog417/items/2791ee878deee0d0fd9c)
    - [双方向性再帰型ニューラルネットワークBidirectional RNN](https://axa.biopapyrus.jp/deep-learning/rnn/brnn.html)
